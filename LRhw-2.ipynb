{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5a0100c2-c664-44a3-b207-4c5e5dd765f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f685d7c-21ac-4fd0-9bc9-3a5aa2726dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52df23c6-4592-4fc8-b555-9f0e4f0e7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y >= 1)\n",
    "X_filtered = X[mask]\n",
    "y_filtered = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f54ae21-f6a0-4bdc-ae0e-234dc6e1598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogReg:\n",
    "    def __init__(self, lr=0.01, epochs=1000):\n",
    "        \"\"\"Инициализация гиперпараметров\"\"\"\n",
    "        self.lr = lr          # Скорость обучения\n",
    "        self.epochs = epochs  # Количество эпох обучения\n",
    "        self.w = None         # Веса модели\n",
    "        self.b = None         # Смещение\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"Сигмоидная функция активации\"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение модели методом градиентного спуска.\n",
    "        Параметры:\n",
    "        X: матица признаков\n",
    "        y: вектор истинных меток\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Инициализация случайных весов и смещения\n",
    "        self.w = np.random.rand(n_features)\n",
    "        self.b = 0\n",
    "        \n",
    "        # Процесс обучения\n",
    "        for _ in range(self.epochs):\n",
    "            # Линейная комбинация признаков и текущих весов\n",
    "            linear_model = np.dot(X, self.w) + self.b\n",
    "            \n",
    "            # Применение сигмоидной функции\n",
    "            predicted = self.sigmoid(linear_model)\n",
    "            \n",
    "            # Производные для обновления весов и смещения\n",
    "            dw = (1/n_samples) * np.dot(X.T, (predicted - y))   \n",
    "            db = (1/n_samples) * np.sum(predicted - y)\n",
    "            \n",
    "            # Обновление весов и смещения\n",
    "            self.w -= self.lr * dw\n",
    "            self.b -= self.lr * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание классов на новых данных.\n",
    "        Параметр:\n",
    "        X: матрица признаков\n",
    "        Возвращает:\n",
    "        y_pred: предсказанные классы\n",
    "        \"\"\"\n",
    "        linear_model = np.dot(X, self.w) + self.b\n",
    "        probabilities = self.sigmoid(linear_model)\n",
    "        y_pred = [1 if prob > 0.5 else 0 for prob in probabilities]\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Оценка доли правильных предсказаний.\n",
    "        Параметры:\n",
    "        X: матрица признаков\n",
    "        y: вектор истинных меток\n",
    "        Возвращает:\n",
    "        accuracy: доля правильных предсказаний\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92931969-a52e-4592-9478-a29bdc14023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4bbb72a-c687-4eb3-9d1f-d3c28bf04cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=CustomLogReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8498458-1718-414c-9a5d-1061ba4abf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eae51450-398c-42f9-affe-20b588c1ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e980dc32-bf29-4453-8585-e913888e726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "480642e8-e473-42ff-be81-e4ddabe531a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "27a7d515-1e96-4bc5-8f8c-a5082677177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionRMSProp:\n",
    "    def __init__(self, learning_rate=0.01, decay_factor=0.9, eps=1e-8, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_factor = decay_factor\n",
    "        self.eps = eps\n",
    "        self.num_iterations = num_iterations\n",
    "        self.theta = None\n",
    "        self.v = None  # Накопленная сумма градиентов\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Добавляем единицу в начало каждого примера для учета свободного члена (bias)\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        \n",
    "        # Инициализация весов случайными значениями\n",
    "        self.theta = np.random.rand(X.shape[1])\n",
    "        self.v = np.zeros_like(self.theta)\n",
    "        \n",
    "        # RMSProp\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Рассчитываем линейную комбинацию\n",
    "            z = np.dot(X, self.theta)\n",
    "            \n",
    "            # Пропускаем через сигмоиду\n",
    "            h = sigmoid(z)\n",
    "            \n",
    "            # Вычисляем градиент функции потерь\n",
    "            gradient = np.dot(X.T, (h - y)) / len(y)\n",
    "            \n",
    "            # Обновляем v — накапливаем средние квадратичные отклонения градиентов\n",
    "            self.v = self.decay_factor * self.v + (1 - self.decay_factor) * (gradient ** 2)\n",
    "            \n",
    "            # Обновляем веса с коррекцией по RMSProp\n",
    "            self.theta -= self.learning_rate * gradient / (np.sqrt(self.v) + self.eps)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Добавляем единицу в начало каждого примера\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        \n",
    "        # Рассчитываем вероятность принадлежности к классу 1\n",
    "        probabilities = sigmoid(np.dot(X, self.theta))\n",
    "        \n",
    "        # Преобразуем вероятности в бинарные предсказания\n",
    "        return np.where(probabilities >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "514a5a50-370e-4a35-a670-a45fcf1db9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logregRMS=LogisticRegressionRMSProp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dafabeff-8b58-47fc-aea6-169f4928a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logregRMS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3bace4c-79be-41a4-88a7-40e898c99b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logregRMS.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4e8a66a7-92d1-481f-aeed-f872148aa338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy using RMSProp: 0.3000\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy using RMSProp: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "149cb861-a798-46d5-984c-4d7012a2dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionNAdam:\n",
    "    def __init__(self, learning_rate=0.01, beta1=0.9, beta2=0.999, eps=1e-8, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.num_iterations = num_iterations\n",
    "        self.theta = None\n",
    "        self.m = None  # Первое среднее (Momentum)\n",
    "        self.v = None  # Второе среднее (Variance)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Добавляем единицу в начало каждого примера для учета свободного члена (bias)\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        \n",
    "        # Инициализация весов случайными значениями\n",
    "        self.theta = np.random.rand(X.shape[1])\n",
    "        self.m = np.zeros_like(self.theta)\n",
    "        self.v = np.zeros_like(self.theta)\n",
    "        \n",
    "        # NAdam\n",
    "        for t in range(1, self.num_iterations + 1):\n",
    "            # Рассчитываем линейную комбинацию\n",
    "            z = np.dot(X, self.theta)\n",
    "            \n",
    "            # Пропускаем через сигмоиду\n",
    "            h = sigmoid(z)\n",
    "            \n",
    "            # Вычисляем градиент функции потерь\n",
    "            gradient = np.dot(X.T, (h - y)) / len(y)\n",
    "            \n",
    "            # Обновляем m и v\n",
    "            self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
    "            self.v = self.beta2 * self.v + (1 - self.beta2) * (gradient ** 2)\n",
    "            \n",
    "            # Исправляем смещенность\n",
    "            m_corr = self.m / (1 - self.beta1 ** t)\n",
    "            v_corr = self.v / (1 - self.beta2 ** t)\n",
    "            \n",
    "            # Обновляем веса с поправкой на Nesterov momentum\n",
    "            self.theta -= self.learning_rate * ((self.beta1 * m_corr) + (1 - self.beta1) * gradient) / (np.sqrt(v_corr) + self.eps)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Добавляем единицу в начало каждого примера\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        \n",
    "        # Рассчитываем вероятность принадлежности к классу 1\n",
    "        probabilities = sigmoid(np.dot(X, self.theta))\n",
    "        \n",
    "        # Преобразуем вероятности в бинарные предсказания\n",
    "        return np.where(probabilities >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "db5aea5b-1710-42ad-9c95-bf0b7f65c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_nadam = LogisticRegressionNAdam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe726741-aa6c-4692-8356-0d09f2d08e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_nadam.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "80aa2404-21e7-4d4c-9593-c0603c008513",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_nadam.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63d99ef1-d195-49c9-8a55-0c514414e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy using NAdam: 0.3000\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy using NAdam: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d6d7535f-af98-49bb-9278-991a5d3c465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты сравнения методов оптимизации:\n",
      "| Метод      | Метрика   | Время работы (секунд) |\n",
      "|------------|-----------|-----------------------|\n",
      "| GD      | 0.3000 |      0.0800 |\n",
      "| RMSProp      | 0.3000 |      0.1199 |\n",
      "| NAdam      | 0.3000 |      0.1379 |\n"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "        {\"method\": \"GD\", \"cls\": CustomLogReg},\n",
    "        {\"method\": \"RMSProp\", \"cls\": LogisticRegressionRMSProp},\n",
    "        {\"method\": \"NAdam\", \"cls\": LogisticRegressionNAdam}\n",
    "    ]\n",
    "    \n",
    "results = []  # список для хранения результатов\n",
    "    \n",
    "for method_dict in methods:\n",
    "    start_time = time.time()  # старт таймера\n",
    "        \n",
    "        # создаем экземпляр модели и выполняем обучение\n",
    "    clf = method_dict[\"cls\"]()\n",
    "    clf.fit(X_train, y_train)\n",
    "        \n",
    "        # измеряем время окончания\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "        \n",
    "        # делаем прогнозы и считаем точность\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # добавляем результаты в таблицу\n",
    "    results.append({\"method\": method_dict[\"method\"], \"metric\": accuracy, \"time\": elapsed_time})\n",
    "    \n",
    "    # Выводим таблицу\n",
    "print(\"Результаты сравнения методов оптимизации:\")\n",
    "print(\"| Метод      | Метрика   | Время работы (секунд) |\")\n",
    "print(\"|------------|-----------|-----------------------|\")\n",
    "for result in results:\n",
    "    print(f\"| {result['method']}      | {result['metric']:.4f} |      {result['time']:.4f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcedf3a-21ee-47df-b9fc-3406bf2f8d85",
   "metadata": {},
   "source": [
    "GD (Gradien Descent): самый быстрый метод с временем около 0.08 секунд.\n",
    "RMSProp: незначительно замедляется по сравнению с GD, демонстрируя время порядка 0.12 секунды.\n",
    "NAdam: занимает наибольшее время среди всех методов — примерно 0.14 секунды.\n",
    "точность одинаковая 0,30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
